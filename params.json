{
  "name": "Hindi Framework",
  "tagline": "A text processing framework for Hindi",
  "body": "# Hindi Text Processing Framework\r\nThe aim of this project is to handle the following tasks for the **HINDI** language :\r\n* **Stop Word Detection**\r\n* **Tokenisation**\r\n* **Sentence Breaking**\r\n* **Identifying Variations**\r\n* **POS Tagging**\r\n* **Concept / Keywords Identification**\r\n* **Entity Recognition**\r\n* **Categorisation**\r\n\r\n## A Bit of on Introduction\r\nThis task was assigned to Team 7 (which is us) as a part of Major Project for the Information Retrieval and Extraction Course. This project was divided into three phases. In the first phase we were required to come up with a scope document and deliverables for the second and the third phase respectively. In the second and third phase, we had to actually code and then implement what we had proposed.\r\n\r\n## Tags\r\n**\\#IIITH** **\\#IIIT-H** **\\#Major_Project** **\\#IRE** **\\#Information_Retrieval_and_Extraction** **\\#Hindi** **\\#StopWordDetection** **\\#POS** **\\#POS_Tagger** **\\#Tokeniser** **\\#Tokenisation** **\\#Sentence_Identifier** **\\#SentenceBreaking** **\\#IdentifyingVariations** **\\#Identify_Variations** **\\#Concept_Identification** **\\#Keywords_Identification** **\\#Entity_Recognition** **\\#NER** **\\#Categorisation** **\\#News_Categories** **\\#Information Retrieval and Extraction Course** **\\#COOL**\r\n\r\n---\r\n    def get_ready():\r\n        print \"IT BEGINS!!\"\r\n    get_ready()\r\n\r\n---\r\n\r\n## Explanation of the Individual Tasks\r\nBelow is an explanation of each individual tasks that we have tried to achieve with this project.\r\n\r\n### Tokenisation\r\nTokenisation is the process of breaking the stream of text into words, phrases or any other important unit for that matter. Those who have had a chance to look at the working of compilers would know this better.   \r\nGiven, that we have a lot of sentences in Hindi, we would want the entire text to be segregated into tokens i.e words. Along with this we would also want that other tokens like dates, designations, abbreviations do retain their original form and don't get messed up.   \r\n### Sentence Breaker\r\nIn Hindi we denote the end of a sentence by what is called a 'purna viraam' which is denoted by 'ред'. Our goal here was to identify that and taking care of all the scenarios, break the entire text into sentences. A given text is hence broken down into sentences and a corresponding id is provided to each one.\r\n### Stop Word Detection\r\nThese are the most common words that can be found in a particular sentence. Generally, these are the words that are very helpful in bringing grammaticality to a particular sentence. Here, two methods have been implemented to find out the different stop word. One of the methods, simply takes a number n, and using that finds a list of top n occurring words across a corpus. The other method relies on **tf-idf** scheme, and requires a corpus which comprises of different documents.\r\n### Part of Speech Tagging\r\nThe task here was to tag a particular using a predefined set of POS tags. It is a method by which the word categories are disambiguated. For this purpose, two models are implemented. One of them follows the **HMM** (Hidden Markov Model). The other one is a **CRF** based model.\r\n### Concept / Keyword Identification\r\nThe task here was to identify the different **NP's** (Noun Phrases). This has been done again by using **HMM**.\r\n### Entity Recognition\r\nThe task here was to identify the different named entities. For this purpose, **CRF** (Conditional Random Fields) were used. A toolkit named CRF++ was utilised for this purpose.\r\n### Categorisation\r\nEvery News article belongs to a set of different categories. Such categories might be politics, entertainment, sports etc. To identify an article's category, a model based on **KNN** (K nearest neighbour) was implemented. The articles were converted into their corresponding vectors using tf-idf method.\r\n### Identifying Variations\r\nThe task here was the identify the variations within the language. Often, it happens, that within the same language, because of some kind of divergence, the spellings of the same words change. Such identification is very important a variety of tasks. In case of Machine Translation, or for that matter in case of any sequence labelling task like NER, we would want to identify these variations in order to improve the accuracy. Hence, for this purpose, a set of rules have been designed which help identify these variations.\r\n\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}